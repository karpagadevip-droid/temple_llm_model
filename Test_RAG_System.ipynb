{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Temple Expert RAG System - Testing Notebook\n",
                "\n",
                "This notebook tests the complete RAG system:\n",
                "- Fine-tuned Llama-3 model (from Hugging Face)\n",
                "- Tavily AI search (real-time information)\n",
                "- Intelligent query routing\n",
                "\n",
                "**Model**: `Karpagadevi/llama-3-temple-expert`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup: Clone Repository & Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone the repository\n",
                "!git clone https://github.com/karpagadevip-droid/temple_llm_model.git\n",
                "%cd temple_llm_model\n",
                "\n",
                "# List files to verify\n",
                "!ls -la"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install -q unsloth transformers accelerate bitsandbytes python-dotenv tavily-python"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration: Set API Keys in .env File"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile .env\n",
                "# Tavily AI API Key (get from https://tavily.com/)\n",
                "TAVILY_API_KEY=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\n",
                "\n",
                "# Hugging Face Token (optional, for private models)\n",
                "HUGGINGFACE_TOKEN=hf_your_token_here\n",
                "\n",
                "# Model to test\n",
                "HUGGINGFACE_MODEL_PATH=Karpagadevi/llama-3-temple-expert"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify .env file created\n",
                "!cat .env"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 1: Tavily Search Only (Fast Test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "\n",
                "from tavily_search import TavilySearcher\n",
                "\n",
                "print(\"Testing Tavily AI Search...\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "searcher = TavilySearcher()\n",
                "results = searcher.search_temple_tickets(\"Meenakshi Temple\")\n",
                "\n",
                "if results['success']:\n",
                "    print(\"\\nâœ… Search successful!\")\n",
                "    print(f\"\\nAI Summary:\\n{results['answer']}\")\n",
                "    print(f\"\\nSources found: {len(results['results'])}\")\n",
                "    \n",
                "    # Show first source\n",
                "    if results['results']:\n",
                "        first = results['results'][0]\n",
                "        print(f\"\\nTop Result:\")\n",
                "        print(f\"  Title: {first['title']}\")\n",
                "        print(f\"  Relevance: {first['score']:.2f}\")\n",
                "        print(f\"  URL: {first['url']}\")\n",
                "else:\n",
                "    print(f\"\\nâŒ Search failed: {results.get('error')}\")\n",
                "    print(\"\\nCheck your TAVILY_API_KEY in .env file\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 2: Load Fine-Tuned Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from model_loader import TempleModelLoader\n",
                "import os\n",
                "\n",
                "print(\"Loading fine-tuned model from Hugging Face...\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"Model: {os.getenv('HUGGINGFACE_MODEL_PATH')}\")\n",
                "print(\"\\nThis may take 2-3 minutes on first run (downloads ~4GB)...\")\n",
                "print()\n",
                "\n",
                "loader = TempleModelLoader()\n",
                "model, tokenizer = loader.load_model()\n",
                "\n",
                "print(\"\\nâœ… Model loaded successfully!\")\n",
                "print(\"\\nTesting with a query...\")\n",
                "\n",
                "response = loader.generate_response(\"Tell me about Meenakshi Temple\", max_length=256)\n",
                "print(f\"\\nModel Response:\\n{response}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 3: Complete RAG System (Model + Search)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag_orchestrator import TempleRAG\n",
                "\n",
                "print(\"=\" * 70)\n",
                "print(\"Initializing Complete RAG System\")\n",
                "print(\"=\" * 70)\n",
                "print()\n",
                "\n",
                "# Initialize RAG with model\n",
                "rag = TempleRAG(\n",
                "    load_model=True,\n",
                "    model_name=os.getenv('HUGGINGFACE_MODEL_PATH')\n",
                ")\n",
                "\n",
                "print(\"\\nâœ… RAG system ready!\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 4: Query Classification & Routing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test different query types\n",
                "test_queries = [\n",
                "    {\n",
                "        'query': \"What is the ticket price for Meenakshi Temple?\",\n",
                "        'expected': 'search',\n",
                "        'explanation': 'Real-time info â†’ uses Tavily search'\n",
                "    },\n",
                "    {\n",
                "        'query': \"Tell me about the history of Meenakshi Temple\",\n",
                "        'expected': 'model',\n",
                "        'explanation': 'Historical info â†’ uses fine-tuned model'\n",
                "    },\n",
                "    {\n",
                "        'query': \"Tell me about Meenakshi Temple and how to visit\",\n",
                "        'expected': 'hybrid',\n",
                "        'explanation': 'Both needed â†’ uses model + search'\n",
                "    }\n",
                "]\n",
                "\n",
                "for i, item in enumerate(test_queries, 1):\n",
                "    print(\"\\n\" + \"=\" * 70)\n",
                "    print(f\"DEMO {i}/3: {item['explanation']}\")\n",
                "    print(\"=\" * 70)\n",
                "    print()\n",
                "    \n",
                "    result = rag.generate_response(item['query'])\n",
                "    \n",
                "    print(f\"Strategy: {result['strategy']} (expected: {item['expected']})\")\n",
                "    print(f\"Source: {result['source']}\")\n",
                "    print(f\"\\nResponse (first 400 chars):\")\n",
                "    response = result['response']\n",
                "    print(response[:400] + \"...\" if len(response) > 400 else response)\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 5: Usage Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "stats = rag.get_stats()\n",
                "tavily_stats = stats['tavily_usage']\n",
                "\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"USAGE STATISTICS\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"Tavily Searches Used: {tavily_stats['searches_used']}/{tavily_stats['free_tier_limit']}\")\n",
                "print(f\"Remaining: {tavily_stats['remaining']} ({100-tavily_stats['percentage_used']:.1f}%)\")\n",
                "print(f\"Model Loaded: {stats['model_loaded']}\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "print(\"\\nâœ… All tests complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 6: Interactive Testing (Try Your Own Queries)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Try your own query!\n",
                "query = input(\"Ask about a temple: \")\n",
                "print()\n",
                "\n",
                "result = rag.generate_response(query)\n",
                "\n",
                "print(f\"\\n{'='*70}\")\n",
                "print(f\"Strategy: {result['strategy']}\")\n",
                "print(f\"Source: {result['source']}\")\n",
                "print(f\"\\nResponse:\\n{result['response']}\")\n",
                "print('='*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Test 7: Compare 60-step vs 600-step Models\n",
                "\n",
                "Run this after your 600-step model finishes training!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment and run after 600-step model is ready\n",
                "\n",
                "# test_query = \"Tell me about Meenakshi Temple\"\n",
                "\n",
                "# print(\"Loading 60-step model...\")\n",
                "# rag_60 = TempleRAG(load_model=True, model_name=\"Karpagadevi/llama-3-temple-expert\")\n",
                "# result_60 = rag_60.generate_response(test_query)\n",
                "\n",
                "# print(\"\\nLoading 600-step model...\")\n",
                "# rag_600 = TempleRAG(load_model=True, model_name=\"Karpagadevi/llama-3-temple-expert-600\")\n",
                "# result_600 = rag_600.generate_response(test_query)\n",
                "\n",
                "# # Compare\n",
                "# print(\"\\n\" + \"=\"*70)\n",
                "# print(\"60-STEP MODEL RESPONSE:\")\n",
                "# print(\"=\"*70)\n",
                "# print(result_60['response'])\n",
                "\n",
                "# print(\"\\n\" + \"=\"*70)\n",
                "# print(\"600-STEP MODEL RESPONSE:\")\n",
                "# print(\"=\"*70)\n",
                "# print(result_600['response'])\n",
                "\n",
                "# print(\"\\n\" + \"=\"*70)\n",
                "# print(\"Which one is better? ðŸ‘†\")\n",
                "# print(\"=\"*70)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}