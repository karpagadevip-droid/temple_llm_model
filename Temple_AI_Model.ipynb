{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Temple Expert - Llama-3 Fine-tuning (600 Steps)\n",
        "\n",
        "This notebook fine-tunes Llama-3-8B on Indian temples dataset.\n",
        "\n",
        "**Training Details:**\n",
        "- Model: Llama-3.1-8B with 4-bit quantization\n",
        "- Method: LoRA (Low-Rank Adaptation)\n",
        "- Steps: 600\n",
        "- Dataset: 100+ temples + refusal examples\n",
        "- GPU: T4 (free on Colab)\n",
        "- Time: ~2 hours\n",
        "\n",
        "**Output:** Model uploaded to `Karpagadevi/llama-3-temple-expert-600`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Clone Repository\n",
        "\n",
        "Get all files from GitHub (includes training script and data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/karpagadevip-droid/temple_llm_model.git\n",
        "%cd temple_llm_model\n",
        "\n",
        "# Verify files are there\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Install Dependencies\n",
        "\n",
        "Install Unsloth and required packages for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Unsloth for fast training\n",
        "!pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install -q --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Set Hugging Face Token\n",
        "\n",
        "**IMPORTANT:** Replace `hf_your_token_here` with your actual Hugging Face token!\n",
        "\n",
        "Get your token from: https://huggingface.co/settings/tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile .env\n",
        "HUGGINGFACE_TOKEN=hf_your_token_here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify .env file created\n",
        "!cat .env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Run Training Script\n",
        "\n",
        "This runs `llama_finetune_colab.py` which:\n",
        "- Loads the dataset (`temples_with_refusals.json`)\n",
        "- Loads Llama-3-8B with 4-bit quantization\n",
        "- Trains for 600 steps (~2 hours)\n",
        "- Tests the model before and after training\n",
        "- Uploads to Hugging Face as `Karpagadevi/llama-3-temple-expert-600`\n",
        "\n",
        "**Just run this cell and wait!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the training script\n",
        "!python llama_finetune_colab.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Complete! ðŸŽ‰\n",
        "\n",
        "Your model is now available at:\n",
        "**https://huggingface.co/Karpagadevi/llama-3-temple-expert-600**\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. **Test the RAG system** with your new model:\n",
        "   - Open `Test_RAG_System.ipynb`\n",
        "   - Run the comparison (Cell 7)\n",
        "   - See 60-step vs 600-step improvement!\n",
        "\n",
        "2. **Share your model**:\n",
        "   - Add a model card on Hugging Face\n",
        "   - Include training details and examples\n",
        "   - Make it public for your portfolio!\n",
        "\n",
        "3. **Continue to Day 5**:\n",
        "   - Agent Architecture\n",
        "   - ReAct pattern\n",
        "   - Tool selection"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}